---
title: "W271 - Assignment3"
author: "Chandra Shekar Bikkanur"
date: "11/22/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
# Load required libraries 
library(car) 
library(dplyr) 
library(Hmisc) 
library(ggplot2) 
library(ggfortify) 
library(plotly) 
library(astsa) 
library(forecast) 
library(fpp2) 
library(GGally) 
library("ggpubr") 
library(gridExtra)
library(grid)
library(xts)
library(tidyverse)
library(xts)
library(vars)
library(zoo)
library(tseries)
```


# Question 1 (1 point): 

**Backshift Operator Expression** 

a. Write down the $ARIMA(2,0,2)(1,0,1)_{4}$ in terms of (1) backshift operators and (2) the fully-expressed form as $y_t$ as a function of lags of $y_t$ and the shock $\omega_t$. 

#### a.1. 
$$
\Theta_1(B^4)\theta_2(B)y_t = \Phi_1(B^4)\phi_2(B)\omega_t
$$

#### a.2.

$$
y_t = \theta_1y_{t-1} + \theta_2y_{t-2} + \Theta_1y_{t-4} + \Theta_2y_{t-5} + \omega_t - \Phi_1 \omega_{t-4} - \phi_1\omega_{t-1} - \phi_2\omega_{t-2}
$$

b. Write down the $ARIMA(2,1,2)(1,0,1)_{4}$ in terms of (1) backshift operators and (2) the fully-expressed form.

#### b.1. 
$$
\Theta_1(B^4)\theta_2(B)(1-B)y_t = \Phi_1(B^4)\phi_2(B)\omega_t
$$

#### b.2.

$$
y_t = y_{t-1} + \theta_1y_{t-1} + \theta_2y_{t-2} + \Theta_1y_{t-4} + \Theta_2y_{t-5} + \omega_t - \Phi_1 \omega_{t-4} - \phi_1\omega_{t-1} - \phi_2\omega_{t-2}
$$


c. Write down the $ARIMA(2,1,2)(1,1,1)_{4}$ in terms of (1) backshift operators and (2) the fully-expressed form.


#### c.1. 
$$
\Theta_1(B^4)\theta_2(B)(1-B^4)(1-B)y_t = \Phi_1(B^4)\phi_2(B)\omega_t
$$

#### c.2.

$$
y_t = y_{t-1} + y_{t-4} +\theta_1y_{t-1} + \theta_2y_{t-2} + \Theta_1y_{t-4} + \Theta_2y_{t-5} + \omega_t - \Phi_1 \omega_{t-4} - \phi_1\omega_{t-1} - \phi_2\omega_{t-2}
$$

**Parameter Redundancy, Stationarity, and Invertibility**

In each of the following cases, (1) check for parameter redundancy and ensure that the $ARMA(p,q)$ notation is expressed in the simplest form, and (2) determine whether they are stationary and/or invertible.

#### a. $y_t = y_{t-1} - \frac{1}{4} y_{t-2} + \omega_t + \frac{1}{2} \omega_{t-1}$

$$ y_t - y_{t-1} + \frac{1}{4} y_{t-2} = \omega_t + \frac{1}{2} \omega_{t-1} $$

$$(1-B+\frac{1}{4}B^2)y_t = (1 + \frac{1}{2}B)\omega_t $$

$$\frac{(4-4B+B^2)}{4}y_t = \frac{(2 + B)}{2}\omega_t $$
$$ (B-2)^2 = 0 ||||(2 + B)=0 $$
$$ (B = 2) ||||B = -2 $$
Here since the roots of $\theta$ and $\phi$ are above unity in absolute value, the process is both stationary and invertible

#### b. $y_t = 2y_{t-1} - y_{t-2} + \omega_t$

$$ y_t - 2y_{t-1} + y_{t-2} = \omega_t $$

$$( 1 - 2B + B^2)y_t = \omega_t $$

$$(B-1)^2y_t = \omega_t $$
$$(B-1)^2 = 0 \implies B = 1 $$
Here since the root of $\theta$ is 1, the process is non-stationary

#### c. $y_t = \frac{7}{10}y_{t-1} - \frac{1}{10} y_{t-2} + \omega_t + \frac{3}{2} \omega_{t-1}$

$$ y_t - \frac{7}{10}y_{t-1} + \frac{1}{10} y_{t-2} = \omega_t + \frac{3}{2} \omega_{t-1} $$

$$ (1 - \frac{7}{10}B + \frac{1}{10} B^2)y_t = (1 + \frac{3}{2} B)\omega_t $$
$$  \frac{(B^2 -7B +10)}{10}y_t = (\frac{2 +3B}{2})\omega_t $$
$$ (B^2 -7B +10) = 0 ||||  B = \frac{-2}{3} $$

$$ B = (1, 5) ||||  B = -0.666 $$

Here since the roots of $\theta$ has a value 1 and $\phi$ has the value below unity in absolute value, the process is neither stationary nor invertible

#### d. $y_t = \frac{7}{10}y_{t-1} - \frac{1}{10} y_{t-2} + \omega_t + \frac{1}{3} \omega_{t-1}$

$$ y_t - \frac{7}{10}y_{t-1} + \frac{1}{10} y_{t-2} = \omega_t + \frac{1}{3} \omega_{t-1} $$

$$ (1 - \frac{7}{10}B + \frac{1}{10} B^2)y_t = (1 + \frac{1}{3} B)\omega_t $$
$$  \frac{(B^2 -7B +10)}{10}y_t = (\frac{3 +B}{3})\omega_t $$
$$ (B^2 -7B +10) = 0 ||||  3 + B = 0 $$

$$ B = (1, 5) ||||  B = -3 $$

Here since the roots of $\theta$ has a value 1 and $\phi$ has the value above unity in absolute value, the process is not stationary but invertible

\newpage

# Question 2: Time series merging and interpolation (2 points)

The file `AMZN.csv` contains Amazon share price data obtained from Yahoo! Finance. The file `UMCSENT.csv` contains the University of Michigan Consumer Sentiment index obtained from the Federal Reserve Economic Database (FRED).

Read `AMZN.csv` and `UMCSENT.csv` into R as dataframes and convert them to time series objects. You may find it advantageous to work with `xts` rather than `ts` objects for the following questions (refer to `xts.Rmd` in the github repo's `live_session_7` folder).

a. Merge the two set of series together, preserving all of the observations in both set of series

b. Fill all of the missing values of the UMCSENT series with -9999
    
c. Create the following new series from the original UMCSENT series:

    - UMCSENT02, replacing all of the -9999 with NAs
    
    - UMCSENT03, replacing the NAs with the last observation
    
    - UMCSENT04, replacing the NAs using linear interpolation
    
    Print a few observations to ensure that your merge as well as the missing value imputation are done correctly. Choose a reasonable number of observations (do not print out the entire dataset).

d. Calculate the daily return of the Amazon closing price, where daily return is defined as $(x_t - x_{t-1})/x_{t-1}$. Plot the daily return series.

e. Create a 20-day and a 50-day rolling mean series from the AMZN close series.

### EDA on AMAZON time-series data

```{r message=FALSE, warning=FALSE}
df_amzn <- read.csv("AMZN.csv", header = TRUE, stringsAsFactors = FALSE)
idx_amzn <- as.Date(df_amzn$Date, format = "%d/%m/%y")
xts_amzn <- xts(df_amzn[, 2:7], order.by = idx_amzn)
str(xts_amzn)
head(xts_amzn, 4)
tail(xts_amzn, 4)
```


### EDA on UMCSENT time-series data
```{r message=FALSE, warning=FALSE}
df_umcsent <- read.csv("UMCSENT.csv", header = TRUE, stringsAsFactors =FALSE)
df_umcsent$UMCSENT <- as.numeric(df_umcsent$UMCSENT)
idx_umcsent <- as.Date(df_umcsent$DATE, format = "%Y-%m-%d")
xts_umcsent <- xts(df_umcsent[, 2], order.by = idx_umcsent)
str(xts_umcsent)
head(xts_umcsent, 4)
tail(xts_umcsent, 4)
```

### 2.a. Merge the two set of series together, preserving all of the observations in both set of series

We will be using the "outer" join method of xts package for merging Amazon data and UMCSENT data 

```{r}
amzn_umcsent_xts <- merge(xts_amzn, xts_umcsent, join = "outer")
head(amzn_umcsent_xts)
tail(amzn_umcsent_xts)
```

### 2.b. Fill all of the missing values of the UMCSENT series with -9999
```{r}
xts_umcsent[is.na(xts_umcsent)] <- -9999
head(xts_umcsent, 10)
```


### 2.c. Create the following new series from the original UMCSENT series:

#### 2.c.i. UMCSENT02, replacing all of the -9999 with NAs

```{r}
UMCSENT02 <- xts_umcsent
UMCSENT02[UMCSENT02 <= -9998] <- NA
cbind(head(xts_umcsent, 4), head(UMCSENT02,4))
```

#### 2.c. ii. UMCSENT03, replacing the NAs with the last observation

```{r}
UMCSENT03 <- na.locf(UMCSENT02, na.rm = TRUE, fromLast = FALSE)
cbind(head(xts_umcsent, 6), head(UMCSENT02,6), head(UMCSENT03,6))
```

#### 2.c. iii. UMCSENT04, replacing the NAs using linear interpolation

```{r}
UMCSENT04 <- UMCSENT02
UMCSENT04 <- na.approx(UMCSENT04, maxgap = 31)
cbind(head(xts_umcsent, 6), head(UMCSENT02,6),  head(UMCSENT03,6), head(UMCSENT04,6))
```

### 2.d. Calculate the daily return of the Amazon closing price, where daily return is defined as $(x_t - x_{t-1})/x_{t-1}$. Plot the daily return series.

```{r message=FALSE, warning=FALSE}
df_amzn1 <- df_amzn[1:5653, 'Close']
df_amzn2 <- df_amzn[2:5654, 'Close']
df_amzn3 <- (df_amzn2 - df_amzn1)/df_amzn1
amzn3_ts <- as.ts(df_amzn3)
cbind(head(df_amzn1, 6),head(df_amzn2, 6),head(df_amzn3, 6))
cbind(tail(df_amzn1, 6),tail(df_amzn2, 6),tail(df_amzn3, 6))

ggplot(amzn3_ts, aes(x = time(amzn3_ts), y = amzn3_ts)) + 
  geom_line(colour = "royalblue") + 
  ggtitle("Daily Retun on Closing Price") + 
  xlab("Time") + ylab("Relative change in Closing Price") 
```

### 2.e. Create a 20-day and a 50-day rolling mean series from the AMZN close series.

```{r message=FALSE, warning=FALSE}
amzn_20day <- list()
for (i in 1:(nrow(df_amzn)-20)){
  amzn_20day_avg <- df_amzn[i:(i+20), 'Close']
  amzn_20day_avg <- mean(amzn_20day_avg)
  amzn_20day <- c(amzn_20day, amzn_20day_avg)
}

amzn_20day.df = data.frame(Reduce(rbind, amzn_20day),row.names = NULL)
amzn_20day_ts <- as.ts(amzn_20day.df)
amzn_20day_plot <- ggplot(amzn_20day_ts, aes(x = time(amzn_20day_ts), y = amzn_20day_ts)) + 
  geom_line(colour = "royalblue") + 
  ggtitle("20-day Rolling Mean Series of Amazon Closing Price") + 
  xlab("Time") + ylab("20-day Mean Price") 


amzn_50day <- list()
for (i in 1:(nrow(df_amzn)-50)){
  amzn_50day_avg <- df_amzn[i:(i+50), 'Close']
  amzn_50day_avg <- mean(amzn_50day_avg)
  amzn_50day <- c(amzn_50day, amzn_50day_avg)
}

amzn_50day.df = data.frame(Reduce(rbind, amzn_50day),row.names = NULL)
amzn_50day_ts <- as.ts(amzn_50day.df)
amzn_50day_plot <- ggplot(amzn_50day_ts, aes(x = time(amzn_50day_ts), y = amzn_50day_ts)) + 
  geom_line(colour = "royalblue") + 
  ggtitle("50-day Rolling Mean Series of Amazon Closing Price") + 
  xlab("Time") + ylab("50-day Mean Price") 

theme_set(theme_gray())
ggarrange(amzn_20day_plot, amzn_50day_plot, ncol = 2, nrow = 1)
```

\newpage

# Question 3: Atmospheric CO2 Concentration (4 points) 

The file `mauna_loa.csv` contains weekly observations of atmospheric carbon dioxide concentration measured at the Mauna Loa observatory in Hawaii, obtained from the National Oceanic and Atmospheric Administration (NOAA), dating from 1974 to 2019.

a. Conduct a thorough EDA of the time series and develop a model that captures both trend and seasonality in the series, following all appropriate steps and conducting suitable diagnostics. Use the model to generate a 2-year-ahead forecast and plot this. In what year does your model predict that atmospheric CO2 will first reach 420 parts per million?

### EDA on MAUNA_LOA time-series data

```{r}
df_noaa <- read.csv("mauna_loa.csv", header = TRUE, stringsAsFactors =FALSE)
df_noaa$Date <-  paste(df_noaa$day, df_noaa$mon, df_noaa$ï..yr, sep="/")
idx_noaa <- as.Date(df_noaa$Date, format = "%d/%m/%Y")
xts_noaa <- xts(df_noaa$CO2.ppm, order.by = idx_noaa)
summary(df_noaa)
str(xts_noaa)
head(xts_noaa)
tail(xts_noaa)
```

```{r}
xts_noaa2 <- xts_noaa
xts_noaa2[xts_noaa2 <= -998] <- NA # replace -999.99 with NAs
xts_noaa3 <- na.locf(xts_noaa2, na.rm = TRUE, fromLast = FALSE)# replace NAs with last oberved value
cbind(xts_noaa["1975-10-05"], xts_noaa2["1975-10-05"], xts_noaa3["1975-10-05"])

ts_noaa <- as.ts(xts_noaa3)
plot(ts_noaa)
plot(xts_noaa3["1975-10-05/1978-10-05"])

```

#### Let us find the best parameters for ARIMA model by applying grid search logic on the cleaned data

```{r message=FALSE, warning=FALSE}
acf(ts_noaa, 3)
pacf(ts_noaa, 3)

best_bic = Inf 
for (d in 0:2){ 
  for (q in 0:4){ 
    for(p in 0:4){ 
     
        ts_noaa.mod <- Arima(ts_noaa, order = c(p,d,q), 
                      seasonal = list(order = c(0,0,0),52),
                      method = "ML",include.drift= TRUE) 
        if (ts_noaa.mod$bic < best_bic){ 
          best_bic = ts_noaa.mod$bic 
          best_p = p 
          best_q = q 
          best_d = d 
          } 
      } 
    } 
  } 
cat("\np:", best_p, "\nd:", best_d, "\nq:", best_q, "\nBIC:", best_bic)

```

#### Let us fit a model and see the diagnostic plots based on the parameters found from the grid search

```{r}
ts_noaa.mod.non.seasonal <- Arima(ts_noaa, order = c(3,1,3), 
                      seasonal = list(order = c(0,0,0),52),
                      method = "ML",include.drift= TRUE)
plot(forecast(ts_noaa.mod.non.seasonal, 104))

par(cex=0.5, mai=c(0.5,0.5,0.5,0.5))
par(fig=c(0.1,0.5,0.1,0.5)) 
acf(ts_noaa.mod.non.seasonal$residuals, main="ACF of the ARIMA Fit's Residual Series")
par(fig=c(0.6, 1,0.1,0.5), new=TRUE) 
pacf(ts_noaa.mod.non.seasonal$residuals, main="PACF of the ARIMA Fit's Residual Series")
par(fig=c(0.1,0.5,0.6,1), new=TRUE) 
hist(ts_noaa.mod.non.seasonal$residuals, main="Histogram of the ARIMA Fit's Residual Series")
par(fig=c(0.6,1,0.6,1), new=TRUE) 
plot(ts_noaa.mod.non.seasonal$residuals, main="ARIMA Fit's Residual Series")
```

CO2 levels will reach 420 ppm on 1975-10-05
```{r}
plot(forecast(ts_noaa.mod.non.seasonal, 179))
lines(x = 1:17816,y=rep(420, 17816),col="green")

paste("CO2 levels will reach 420 ppm on ", as.Date("1975-10-05") + 17816, sep = "")

```

#3.b. Load the `co2` dataset from the R's `datasets` package. This is a time series of monthly observations from 1959 to 1997. Use averages from the NOAA data to extend the monthly series to 2019. Repeat the previous analysis and forecast for this monthly 1959-2019 series. Assess your model's pseudo-out-of-sample forecasting performance using a rolling test set window, and plot the distribution of RMSEs over this range of test sets. 

```{r}
data(co2)
ts.plot(co2)
xts_noaa_ep <- endpoints(xts_noaa3, on = "months")
xts_noaa_monthlyMean <- round(period.apply(xts_noaa3, INDEX = xts_noaa_ep, FUN = mean),2)
xts_noaa_post_1998 <- xts_noaa_monthlyMean["1998-01-25/2019-09-22"]
ts_noaa_post_1998_df <- as.ts(xts_noaa_post_1998)
noaa_post_1998_df <- as.data.frame(as.numeric(ts_noaa_post_1998_df))

co2_df <- as.data.frame(as.numeric(co2)) 
colnames(co2_df) <- "x"
colnames(noaa_post_1998_df) <- "x"

df_co2_total <- rbind(co2_df, noaa_post_1998_df)
ts_co2_total <- ts(df_co2_total, start = c(1959, 1), end = c(2019, 9), frequency = 12)
ts.plot(ts_co2_total)
```


```{r message=FALSE, warning=FALSE}
acf(ts_co2_total, 3)
pacf(ts_co2_total, 3)

best_bic = Inf 
for (d in 0:2){ 
  for (q in 0:4){ 
    for(p in 0:4){ 
     
        ts_co2_total.mod <- Arima(ts_co2_total, order = c(p,d,q), 
                      seasonal = list(order = c(0,0,0),52),
                      method = "ML",include.drift= TRUE) 
        if (ts_co2_total.mod$bic < best_bic){ 
          best_bic = ts_co2_total.mod$bic 
          best_p = p 
          best_q = q 
          best_d = d 
          } 
      } 
    } 
  } 
cat("\np:", best_p, "\nd:", best_d, "\nq:", best_q, "\nBIC:", best_bic)

```
```{r}
ts_co2_total.mod.non.seasonal <- Arima(ts_noaa, order = c(4,1,4), 
                      seasonal = list(order = c(0,0,0),52),
                      method = "ML",include.drift= TRUE)
plot(forecast(ts_co2_total.mod.non.seasonal, 104))

par(cex=0.5, mai=c(0.5,0.5,0.5,0.5))
par(fig=c(0.1,0.5,0.1,0.5)) 
acf(ts_co2_total.mod.non.seasonal$residuals, main="ACF of the ARIMA Fit's Residual Series")
par(fig=c(0.6, 1,0.1,0.5), new=TRUE) 
pacf(ts_co2_total.mod.non.seasonal$residuals, main="PACF of the ARIMA Fit's Residual Series")
par(fig=c(0.1,0.5,0.6,1), new=TRUE) 
hist(ts_co2_total.mod.non.seasonal$residuals, main="Histogram of the ARIMA Fit's Residual Series")
par(fig=c(0.6,1,0.6,1), new=TRUE) 
plot(ts_co2_total.mod.non.seasonal$residuals, main="ARIMA Fit's Residual Series")
```


# Question 4: Vector Autoregression (3 points)

Use the series contained in `Q4.txt` to conduct a multivariate time series analysis and build a model to forecast the series. In model estimation, do not use the observations in 1993. All relevant time-series model building steps are applicable. Measure and discuss your model's performance, using both in-sample and out-of-sample model performance. When training your model, exclude all the observations in 1993. For the out-of-sample forecast, measure your model's performance in forecasting 1993. Discuss the model performance and forecast a 12-month forecast beyond the last observed month in the given series.


Let us load the "Q4.txt" data into a data-frame and convert it into a time-series (ts) object "df_q4_ts".  
```{r message=FALSE, warning=FALSE}
df_q4 <- read.table("Q4.txt",header = TRUE, stringsAsFactors = FALSE)
df_q4_ts <- ts(df_q4[, 3:6], start=c(1947,1),end = c(1993,12), frequency= 12)
str(df_q4_ts)

```

Let us now segregate the time-series "df_q4_ts" into training and testing data.

```{r message=FALSE, warning=FALSE}
df_q4_test <- window(df_q4_ts, start= c(1993, 1))
df_q4_train <- window(df_q4_ts, end= c(1992, 12))
```

Let us now plot the time-series to see the distribution of 4 series
```{r}
autoplot(df_q4_ts, main = "Q4 Time Series Data")
```

Let us now see the correlation among of all 4 series present in the "df_q4_ts"
```{r}
scatterplotMatrix(~df_q4_ts[, 1] + df_q4_ts[, 2] + df_q4_ts[, 3] +
df_q4_ts[, 4])
```

Let us now plot  1. Histogram ; 2. time-series plot, 3. ACF and 4. PACF of all 4 series.
```{r}
tsplot <- function(series, title) {
par(mfrow = c(2, 2))
hist(series, main = "")
title(paste(title, "Histogram"))
plot.ts(series, main = "")
title(paste(title, "Time-Series Plot"))
acf(series, main = "")
title(paste("ACF", title))
pacf(series, main = "")
title(paste("PACF", title))
}
tsplot(df_q4_ts[, 1], "Series1")
tsplot(df_q4_ts[, 2], "Series2")
tsplot(df_q4_ts[, 3], "Series3")
tsplot(df_q4_ts[, 4], "Series4")
```

Let us now see how much correlation exists among all 4 series.
```{r}
par(mfrow = c(1, 1))
corrfunc <- function(series1, series2) {
cat("Correlation Matrix: ", cor(series1, series2))
ccf(series1, series2)
}

for (i in 1:4) {
     for (j in 1:4) {
       if (i != j & j > i) {
           corrfunc(df_q4_ts[, i], df_q4_ts[, j])
           }
       }
}
```

We need to fit a Vector Autoregressive Model; so, let us find out what would be the regressive paramter (p) would be based on the least BIC score aka SC score.
```{r}
VARselect(df_q4_train, lag.max = 8, type = "both")
```

We see that "SC" score for parameter 2 is lowest (-7.3533473347) in top 8 paramters. So, we will model a VAR based on p = 2.
```{r}
var.fit1 <- VAR(df_q4_train, p = 2, type = "both")
summary(var.fit1)
```

Let us check the roots of the model to verify if the model/process is stable. If all the roots are less than one, the process is said to be stable. 
```{r}
roots(var.fit1)
var.fit1.ptasy <- serial.test(var.fit1, lags.pt = 12, type = "PT.asymptotic")
var.fit1.ptasy

```

Let us now forecast the fitted model until the psudo-out-of-sample data.
```{r}
forecast(var.fit1, 12) %>% autoplot() + xlab("Year")
```

Let us now refit the model with p= 2 on the entire data and forecast 1 more year (= 12 months)
```{r}
var.fit.total <- VAR( df_q4_ts, p=2, type = "both" ) 
var.fit.total %>% predict(n.ahead = 12, ci = 0.95) %>% autoplot()
```
  
